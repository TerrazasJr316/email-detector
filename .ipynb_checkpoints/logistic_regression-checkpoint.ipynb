{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6792557-1867-44c3-b919-2b0665232fc5",
   "metadata": {},
   "source": [
    "# Regresión Lógistica: Detección de SPAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0da4bd-4f02-42d3-81ad-569063e55630",
   "metadata": {},
   "source": [
    "En este ejercicio se muestran los fundamentos de la **Regresión Logística** planteando uno de los primeros problemas que fueron solucionados mendiante el uso de técnicas de Machine Learnin: La Detección de SPAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0945d9e-ce97-49f8-bd10-057fe995d8ab",
   "metadata": {},
   "source": [
    "## Enuncido del ejercicio\n",
    "\n",
    "Se propone la contrucción de aprendizaje automático capaz de predecir si un correo determinado se SPAM o no, para esto se utilizará el siguiente DataSet (Conjunto de Datos):\n",
    "\n",
    "##### [2007 TREC Public Spam Corpurs](https://plg.uwaterloo.ca/~gvcormac/treccorpurs07/)\n",
    "The corpus trec07p contains 75,419 messages:\n",
    "\n",
    "    25220 ham\n",
    "    50199 spam\n",
    "\n",
    "These messages constitute all the messages delivered to a particular\n",
    "server between these dates:\n",
    "\n",
    "    Sun, 8 Apr 2007 13:07:21 -0400\n",
    "    Fri, 6 Jul 2007 07:04:53 -0400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2a62aa-ad9e-4c83-a99e-cc70c416b9fc",
   "metadata": {},
   "source": [
    "## 1. Funciones Complementarios\n",
    "\n",
    "permitirá preposesar los datos calitativaos en datos cauntitaticos\n",
    "\n",
    "En este caso práctico con la detección de correos electrónicos SPAM, el DataSet del que se disponem esta formado por correos electrónicos, con sus correspondientes cabeceras y campos adicionales. Por lo tanto, requieren un preprocesamiento previo antes de que sean ingeridos por un Modelo de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfc8ea5a-4989-46d2-9792-5270e81447b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta clase facilita el preprocesamiento de correos electrónicos que poseen códigos HTML\n",
    "\n",
    "from html.parser import HTMLParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4eff028-3a7e-4496-a822-62cbd625435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset() # Cada vez que reciba un correo limpeara la memoria \n",
    "        self.strict = False # \n",
    "        self.convert_charrefs = True # Controla las referencia de caracteries HTML (eliminar ligas)\n",
    "        self.fed = [] # Crear una lista vacía dentro del objeto self\n",
    "\n",
    "    def handle_data (self, d): # función d va a guardar el codgio html en el obejto self guardarlo en texto plano\n",
    "        self.fed.append(d)\n",
    "\n",
    "    def get_data (self): # Recuperar los datos en el objetos self guardados en la lista fed\n",
    "        return ''.join(self.fed) # Extaer todos los correos en el objeto self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5953d141-6166-434b-a8c4-1f647b283983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función se encarga de eliminar los Tags HTML que se encuentren en el texto del correo electrónico\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper() # \n",
    "    s.feed(html) # Devolvera los correos sin Tags pero bien estructurados\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "097fa54d-b42c-4984-9a5d-6bcd2211d737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Phrack World News'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ejemplo de eliminacion de los tags de HTML de un texto\n",
    "t = '<tr><td align=\"left\"><ahref=\"../../.issues/51/16.html#article\">Phrack World News</a><td>'\n",
    "strip_tags(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4a8204-1378-4483-96e4-65314729661c",
   "metadata": {},
   "source": [
    "Ademas de eliminar los posibles tags HTML que se encuentran en el correo electronico, deben realizarse otras acciones de preprocesamiento para evitar que  los mensajes contengan ruido inecesario. Entre ellas se encuentran la eliminacion de los signos de puntuacion, eliminación de los posibles campos de correo electronico que no son relevantes o eliminación de los afijos de una palabra manteniendo unicamente la raiz de la misma (Stemming). La clase que se muestra a continuación realiza estas transformaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6e8f350-248c-4c48-9a6a-e361751ea3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "class Parser:\n",
    "    def __init__(self):\n",
    "        self.stemmer = nltk.PorterStemmer() \n",
    "        self.stopwords = set(nltk.corpus.stopwords.words('english')) \n",
    "        self.punctuation = list(string.punctuation) # bascar todos los signos de puntuación\n",
    "    def parse(self, email_path): # regresar la ruta del email\n",
    "        \"\"\"Parse an Email\"\"\" # recordar que las comillas triples es declarar la variable pero ahorrando la variable\n",
    "        with open(email_path, errors = 'ignore') as e: \n",
    "            msg = email.message_from_file(e)\n",
    "        return None if not msg else self.get_email_content(msg) # si encuentra un error en la ruta del email retornara un mensaje de error\n",
    "    def get_email_content(self, msg): \n",
    "        \"\"\"Extract the email content.\"\"\" \n",
    "        subject = self.tokenize(msg['Subject']) if msg ['Subject'] else [] # Se buscara lo que se quiere extraer del email\n",
    "        body = self.get_email_body(msg.get_payload(),\n",
    "                                    msg.get_content_type())  \n",
    "        content_type = msg.get_content_type() # se esta diciendo que es lo que va a encontrar,\n",
    "        # Return the contentm of the email\n",
    "        return {\"subject\": subject,\n",
    "               \"body\": body,\n",
    "               \"content_type\":content_type} # retornando el subject, el body y el content type \"una lista\"\n",
    "    def get_email_body(self, payload, content_type): # estos son los parametros que contiene el email\n",
    "        \"\"\"Extract the body of the email.\"\"\"\n",
    "        body = []\n",
    "        if type(payload) is str and content_type == 'text/plain':  \n",
    "            return self.tokenize(payload) # OCR \n",
    "        elif type(payload) is str and content_type == 'text/html':\n",
    "            return self.tokenize(strip_tags(payload))\n",
    "        elif type(payload) is list:\n",
    "            for p in payload:\n",
    "                body += self.get_email_body(p.get_payload(),\n",
    "                                           p.get_content_type())\n",
    "        return body\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Transform a text string in tokens. Perform two main actions, clean the puntuaction symbols and do stemming of the text\"\"\"\n",
    "        for c in self.punctuation:\n",
    "            text = text.replace(c, \"\")\n",
    "        text = text.replace(\"\\t\", \" \")\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        tokens = list(filter(None, text.split(\" \")))\n",
    "        # Stemming of the tokens\n",
    "        return [self.stemmer.stem(w) for w in tokens if w not in self.stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ca126-26dc-47fb-a9a4-e167ddcf7286",
   "metadata": {},
   "source": [
    "#### Lectura en formato .raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a25341-2531-486f-8a6f-29641831f48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From RickyAmes@aol.com  Sun Apr  8 13:07:32 2007\n",
      "Return-Path: <RickyAmes@aol.com>\n",
      "Received: from 129.97.78.23 ([211.202.101.74])\n",
      "\tby speedy.uwaterloo.ca (8.12.8/8.12.5) with SMTP id l38H7G0I003017;\n",
      "\tSun, 8 Apr 2007 13:07:21 -0400\n",
      "Received: from 0.144.152.6 by 211.202.101.74; Sun, 08 Apr 2007 19:04:48 +0100\n",
      "Message-ID: <WYADCKPDFWWTWTXNFVUE@yahoo.com>\n",
      "From: \"Tomas Jacobs\" <RickyAmes@aol.com>\n",
      "Reply-To: \"Tomas Jacobs\" <RickyAmes@aol.com>\n",
      "To: the00@speedy.uwaterloo.ca\n",
      "Subject: Generic Cialis, branded quality@ \n",
      "Date: Sun, 08 Apr 2007 21:00:48 +0300\n",
      "X-Mailer: Microsoft Outlook Express 6.00.2600.0000\n",
      "MIME-Version: 1.0\n",
      "Content-Type: multipart/alternative;\n",
      "\tboundary=\"--8896484051606557286\"\n",
      "X-Priority: 3\n",
      "X-MSMail-Priority: Normal\n",
      "Status: RO\n",
      "Content-Length: 988\n",
      "Lines: 24\n",
      "\n",
      "----8896484051606557286\n",
      "Content-Type: text/html;\n",
      "Content-Transfer-Encoding: 7Bit\n",
      "\n",
      "<html>\n",
      "<body bgcolor=\"#ffffff\">\n",
      "<div style=\"border-color: #00FFFF; border-right-width: 0px; border-bottom-width: 0px; margin-bottom: 0px;\" align=\"center\">\n",
      "<table style=\"border: 1px; border-style: solid; border-color:#000000;\" cellpadding=\"5\" cellspacing=\"0\" bgcolor=\"#CCFFAA\">\n",
      "<tr>\n",
      "<td style=\"border: 0px; border-bottom: 1px; border-style: solid; border-color:#000000;\">\n",
      "<center>\n",
      "Do you feel the pressure to perform and not rising to the occasion??<br>\n",
      "</center>\n",
      "</td></tr><tr>\n",
      "<td bgcolor=#FFFF33 style=\"border: 0px; border-bottom: 1px; border-style: solid; border-color:#000000;\">\n",
      "<center>\n",
      "\n",
      "<b><a href='http://excoriationtuh.com/?lzmfnrdkleks'>Try <span>V</span><span>ia<span></span>gr<span>a</span>.....</a></b></center>\n",
      "</td></tr><td><center>your anxiety will be a thing of the past and you will<br>\n",
      "be back to your old self.\n",
      "</center></td></tr></table></div></body></html>\n",
      "\n",
      "\n",
      "----8896484051606557286--\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inmail = open(\"ALERT/datasets/datasets/trec07p/data/inmail.1\").read()\n",
    "print(inmail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67accb37-1c1a-458a-afd1-b5712fddbb44",
   "metadata": {},
   "source": [
    "#### Parsing del email\n",
    "\n",
    "```\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "```\n",
    "\n",
    "Establecer ruta personalizada:\n",
    "\n",
    "```\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "route_download = \"/home/terrazas/Documentos/GitHub/machine-learning-aplication/nuevos/nltk_data\"\n",
    "nltk.download('stopwords', download_dir=route_download)\n",
    "\n",
    "if route_download not in nltk.data.path:\n",
    "    nltk.data.path.append(route_download)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9853fc4-5144-4c71-9107-c3fdb5d1b22b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': ['gener', 'ciali', 'brand', 'qualiti'],\n",
       " 'body': ['do',\n",
       "  'feel',\n",
       "  'pressur',\n",
       "  'perform',\n",
       "  'rise',\n",
       "  'occas',\n",
       "  'tri',\n",
       "  'viagra',\n",
       "  'anxieti',\n",
       "  'thing',\n",
       "  'past',\n",
       "  'back',\n",
       "  'old',\n",
       "  'self'],\n",
       " 'content_type': 'multipart/alternative'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "\n",
    "p = Parser() # Realizar el preprocesamiento\n",
    "p.parse(\"ALERT/datasets/datasets/trec07p/data/inmail.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5572d9c-4c29-40ca-a008-6577b128293a",
   "metadata": {},
   "source": [
    "#### Lectura del índice\n",
    "\n",
    "Estas funciones complementarias se encargar de cargar en memoria la ruta de cada correo electrónico y su etiqueta correspondiente {spam, ham}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32aa2eb-2528-465d-8e07-cb242941ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = open(\"ALERT/datasets/datasets/trec07p/full/index\").readlines()\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1ecf81-d308-437b-9b72-44235d35d003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DATASET_PATH = \"ALERT/datasets/datasets/trec07p\"\n",
    "\n",
    "def parse_index(path_to_index, n_elements):\n",
    "    ret_indexes = [] # en esta arreglo se mostraran \n",
    "    index = open(path_to_index).readlines()\n",
    "    for i in range(n_elements):\n",
    "        mail = index[i].split(\" ../\")\n",
    "        label = mail[0] # trayendo su etiqueta\n",
    "        path = mail[1][:-1] # iniciará en la primera posición del arreglo hasta la ultima posición del arreglo\n",
    "        ret_indexes.append({\"label\" : label, \"email_path\": os.path.join(DATASET_PATH, path)}) # .append sirve para insertar en un diccionario, con su etiqueta si es 'spam' o no \n",
    "    return ret_indexes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e0a6ee-5090-466d-b9a9-781067d13bf6",
   "metadata": {},
   "source": [
    "infraestructura para bases de datos usar la skill \"airbyte\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aefcd61-d962-4098-a2d4-a560fabbf79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_email(index):\n",
    "    p = Parser()\n",
    "    pmail = p.parse(index[\"email_path\"]) # \n",
    "    return pmail, index[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba86faec-36f7-4e14-92f6-1be95cd85bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = parse_index(\"ALERT/datasets/datasets/trec07p/full/index\", 10)\n",
    "indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0846cc77-3495-4879-82d0-e0cfa77b3d3a",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento del DataSet\n",
    "\n",
    "Con las funciones presentadas anteriormente se permite la lectura de los correos electrónicos de manera programática y el procesamiento de los mismos para eliminar aquellos componentes que no resultan de utilidad para la detección de correos de SPAM. Sin embargo cada uno de los correos sigue estando representado por un diccionario de Python con una serie de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa34eef-1201-42bf-9f36-edad5366163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el indice y las etiquetas en memoria\n",
    "index = parse_index(\"ALERT/datasets/datasets/trec07p/full/index\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452aadb4-4c8f-4475-9102-1b23f101b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el primer correo\n",
    "import os\n",
    "\n",
    "open(index[0][\"email_path\"]).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89afbfdf-b831-4c52-8871-a2acd3c5fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsear el primer correo\n",
    "mail, label = parse_email(index[0])\n",
    "print(\"El correo es: \",label, \"\\n\")\n",
    "print(mail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea44e89-5f67-40ca-8a03-a4958bf1ced5",
   "metadata": {},
   "source": [
    "el algoritmo de regresión logística no es capaz de ingerir texto como parte del DataSet. Por lo tanto, genera aplicarse una serie de funciones adicionales que transformen el texto de los correos electronicos parseados en una representacion numérica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c15045f-1f31-4cc2-893d-072df69a5009",
   "metadata": {},
   "source": [
    "### Aplicación de CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03bbd01-6b21-4f09-9699-7bc1ed72164b",
   "metadata": {},
   "source": [
    "El **CountVectorizer** es una clase de Python de la biblioteca de scikit-learn utilizada para convertir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be83960-3af3-4bb2-9b20-b0c06c7fb723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Preparación del email en una cadena de texto.\n",
    "prep_email = [\" \".join(mail['subject']) + \" \".join(mail['body'])] # preparamos el email con el subject y el body.\n",
    "\n",
    "vectorizer = CountVectorizer() # declaramos una variable ocupando la clase CountVectorizar \n",
    "X = vectorizer.fit(prep_email) \n",
    "\n",
    "print(\"e-mail:\", prep_email, \"\\n\")\n",
    "print(\"Caracteristicas de entrada: \", vectorizer.get_feature_names_out()) # Extraer con CountVectorizer las características entrada\n",
    "\n",
    "# Extrae los tokens en un solo arreglo \n",
    "# Recordar que la función de hipótesis necesita en función de x a y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb04895-d871-4d56-835b-030d73a1cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.transform(prep_email)\n",
    "print(\"\\nValues:\\n\", X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf64ea41-b511-478f-ad53-1c4d5b773406",
   "metadata": {},
   "source": [
    "Porque aparecen puros uno, esta cotejando en si msimo, es decir, se esta evaluando el correo con el mismo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45177d7b-2c81-4886-9deb-628d0937194f",
   "metadata": {},
   "source": [
    "#### Aplicacion de OneHotEncoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922e768-f21b-44a8-9f41-eb8fcd743036",
   "metadata": {},
   "source": [
    "El **OneHotEncoding** es una técnica para representar datos categorícos como vectores binarios. Extrae la características de entrada y las convierte en categorías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bce1b46-e139-484a-a8e3-60c356a29db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "prep_email = [[w] for w in mail['subject'] + mail['body']] # w se refiere a 'words' \n",
    "enc = OneHotEncoder(handle_unknown = 'ignore') \n",
    "X = enc.fit_transform(prep_email)\n",
    "\n",
    "print(\"Features:\\n\", enc.get_feature_names_out(), \"\\n\")\n",
    "print(\"\\nValues:\\n\", X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca94d9-4f0d-494e-ad2f-f541f75bd66e",
   "metadata": {},
   "source": [
    "### Funciones auxiliares para le preprocesamiento del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd39610-a4e3-4c95-9f96-a2caabce65a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prep_dataset(index_path, n_elements):\n",
    "    X = []\n",
    "    y = []\n",
    "    indexes = parse_index(index_path, n_elements)\n",
    "    for i in range(n_elements):\n",
    "        print(\"\\rParsing email: {0}\".format(i + 1),end = '')\n",
    "        mail, label = parse_email(indexes[i])\n",
    "        X.append(\" \".join(mail['subject']) + \" \".join(mail['body']))\n",
    "        y.append(label)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abe71de-06fc-43c4-be32-ac330c461f4f",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c879f-e42b-4eea-b130-4ddac0687aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer únicamente un subconjunto de 100 correos electronicos\n",
    "X_train, y_train = create_prep_dataset(\"ALERT/datasets/datasets/trec07p/full/index\", 100)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9e06a4-a706-4833-afd3-e2409cc8a9bb",
   "metadata": {},
   "source": [
    "### Aplicar la Vectorización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f41ca7-4c67-4aa9-a015-26e5c95fab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train= vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978cd09a-5efe-48a6-8556-4cc4878ab4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.toarray()) # Todos los tokens que logro extrar de los 100 correos conviertidos ya en numeros por el CountVectorizer\n",
    "print(\"\\nFeatures\", len(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97675aca-b160-4c30-904b-4f1d03d662db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(X_train.toarray(), columns=[vectorizer.get_feature_names_out()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab7aeab-fd9a-4b05-ad10-7922ca092ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train # Mostrar las etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf3ce4f-104e-4369-a417-1c3a4740fb7a",
   "metadata": {},
   "source": [
    "#### Entrenamiento del Algoritmo de Regresión Logistica con el DataSet Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b597ccd-9531-4525-bdc4-165d2bcb35ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression() # clf será el 'clasificador'\n",
    "clf.fit(X_train, y_train) # De forma que lo esta entrenando"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3d8e40-4b85-4ae5-9089-f21d0554d305",
   "metadata": {},
   "source": [
    "Estudiar ITIL, COBIT, PMBook, Gobierno de TI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89d1c91-1d23-4f55-9e6c-2ee35c07792c",
   "metadata": {},
   "source": [
    "## 4.- Predicción\n",
    "\n",
    "Lectrua de un DataSer nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5e450-4d57-4fed-84fe-e9903878b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de un DataSet de correos nuevos.\n",
    "\n",
    "# Leer 150 correos del DataSet y quedarnos unicamente con los 50 últimos correos electrónicos, los cuales no se han utilizado para entrenar el algoritmo.\n",
    "X, y = create_prep_dataset(\"ALERT/datasets/datasets/trec07p/full/index\", 150) # Se esta leyendo los 150 datos\n",
    "X_test = X[100:] # Se empiza con 100 porque el entrenamiento ya se hizo con 100 correos\n",
    "y_test = y[100:] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ac0bb-0775-44cc-a4ad-79ea826909d4",
   "metadata": {},
   "source": [
    "### Procesamiento de los correos electrónicos con el vectorizador creado anteriomente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6646197-6f47-4967-be1f-f12d3ac19015",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa30430-9664-4c59-9d5c-2968f1d6591a",
   "metadata": {},
   "source": [
    "#### Predicción del tipo de correo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5a9409-7ee7-4312-aba8-04289a2bc2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295c5e8-d5c7-4fe5-a3c0-3da251b8f6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicción\\n\", y_pred)\n",
    "print(\"\\nEtiquetas Reales\\n\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2285406e-338c-4318-b9aa-82746d15d402",
   "metadata": {},
   "source": [
    "### Evaluación de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726cf9f9-6994-4408-ad2f-f7c1c8933fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f353c6-59c8-4c3d-a516-fd4fbbd9f99e",
   "metadata": {},
   "source": [
    "## 5. Aumentando el DataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a251c9-9e49-4571-b9b9-acdb567aa439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer 12,000 correos electrónicos\n",
    "\n",
    "X, y = create_prep_dataset(\"ALERT/datasets/datasets/trec07p/full/index\", 12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f874924-4d06-4196-a5d9-e4dfba085502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos 10,000 para entrenar el algoritmo y 2,000 para realizar pruebas.\n",
    "X_train, y_train = X[:10000], y[:10000]\n",
    "X_test, y_test = X[10000:], y[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7283cc0-631a-4bd2-ba07-b93d3b5d5444",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a35cb69-b055-43ea-b6f1-ea16e78411a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31956129-3792-421f-8e39-d8be8974045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(X_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
